\chapter{Related work}

Automated domain modeling encompasses two primary research directions: rule-based methods and statistical methods.

Rule-based methods usually contain hand-written rules and heuristics to automatically identify model elements in a given domain description. For example, \citet{Raharjana2021} and \citet{Sonbol2022} provide recent field surveys for further details.

Statistical methods typically use machine learning techniques to based on a given domain description to either generate the complete domain model \cite{Chen2023,Saeedizade2024} or to start from some smaller domain model and based on the user's instructions to iteratively generate a completed domain model \cite{Camara2023} or to suggest only specific components that the user can build his domain model with.

In the section \ref{section:ref_recent_approaches_using_llms} we dive deeper into recent approaches to automated domain modeling with LLMs and then in the section \ref{section:llm_as_an_assistant} we examine approaches that use LLMs as an assistant.


\section{Recent approaches using LLMs}
\label{section:ref_recent_approaches_using_llms}

\citet{Camara2023} experiment with ChatGPT-3.5 to generate domain models in PlantUML format. Their experiments demonstrate that generating complete domain models comprising more than 8 to 10 classes results into unusable domain models. However, they show that it works better to start from a smaller domain model and then iteratively enhance it based on user's instructions.

\citet{Fill2023} and \citet{Haerer2023} additionally explore abilities of ChatGPT-4 in generating domain models and they experiment with different output formats. \citet{Fill2023} conclude that the LLMs show enormous potential for modeling tasks and the \citet{Haerer2023} concludes that their results show that iterative modeling in a conversational dialogue could be practical, however, further systematic evaluations need to be conducted.

\citet{BabaeiGiglou2023} experiment with different types of LLMs and concludes that ChatGPT-4 usually provides the best output quality for domain modeling tasks.

\citet{Chen2023} evaluate generating classes, attributes and associations with 0-shot prompting, N-shot prompting and chain of thoughts with ChatGPT-3.5 and ChatGPT-4. They conclude that the combination of N-shot prompting with ChatGPT-4 achieved the best results however, they also add that fully domain modeling still remains impractical.

\citet{Saeedizade2024} try many different step by step prompting methods to iteratively generate complete domain model. Their experiments reveal that using their iterative step by step prompting technique ``Competency Question by Competency Question'' with ChatGPT-4 outperforms the average quality of the initial submission of novice ontology engineering students. 


\section{Using LLM as an assistant}
\label{section:llm_as_an_assistant}

Applications that use LLM as an assistant such as GitHub Copilot\footnote{\url{https://github.com/features/copilot}}, Microsoft Office Copilot\footnote{\url{https://www.microsoft.com/en-us/microsoft-copilot}}, Grammarly\footnote{\url{https://app.grammarly.com/}} and Notion AI\footnote{\url{https://www.notion.so/product/ai}}, have the following features in common.

First, the LLM provides only suggestions that the user can accept, reject, or in some cases regenerate a new suggestion. The reason is that the LLMs still make a lot of mistakes so direct application of their output is not wanted. Furthermore, these mistakes can accumulate over time and create even worse output.

Second, the suggestions are usually in a form such that the user can quickly decide if he wants to use them. For example, in Grammarly each mistake is underlined and a reason is provided. In GitHub Copilot it is usually a simple task to decide if suggested comment or code is relevant and so on.


\chapter{Related work discussion}

As we mentioned in the section \ref{section:ref_recent_approaches_using_llms}, fully automatic domain modeling works only for domain descriptions with small amount of domain elements even when the LLM is generating the output iteratively step by step \cite{Saeedizade2024}. This issue can be mitigated by including the user into the domain modeling process \cite{Camara2023} and using the LLM as an assistant. For example, \citet{Camara2023} tried using LLM as an assistant where the LLM generates some preliminary domain model and the user inputs following instructions to edit his domain model. However, the LLM executed directly each user's instruction that lead frequently to back-and-forth communication with the LLM to repair the mistakes it made. Additionally, the user did not have an option to manually model the parts of domain model that for example the LLM struggled with.

To address the mentioned issues in our thesis we let the user to manually create his domain model with the help of the LLM as an assistant. To improve the performance of the LLM we divide the domain modeling process into a set of simpler steps and we employ the RAG technique for filtering domain description.

This assistant always generates output in form of suggestions as the LLM can make some mistake any time. To help the user decide if he wants to apply generated suggestions we highlight each generated element in the given domain description. This is done by letting the LLM generate exact citation from the domain description which is then automatically found in the given domain description.
