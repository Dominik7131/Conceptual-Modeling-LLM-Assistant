\section{Retrieval-augmented generation}

The domain description $T$ is the knowledge base and our goal is to insert only the relevant parts of the $T$ to the context specification part of the prompt. We use this technique for generating attributes and associations as the LLM needs only the information about the given class $C$ and in some cases also the information about the given class $D$.

For example, if in domain description the first sentence informs us about employees and the second sentence informs us about projects, when suggestion attributes for the class ``employee'' we insert only the first sentence in the prompt. This is mainly done to reduce the hallucination of the LLM. But it can also help to reduce the prompt length when working with a domain description that does not fit into the context window size of the LLM. \\

TODO: Brief chapter description \\


\subsection{Challenges}

Now we will describe the most significant challenges we encountered and the corresponding solutions we implemented to address them.

\subsubsection{Domain description segmentation}

First, the domain description needs to be split into chunks so each chunk can be evaluated if it is relevant for the provided classes.

Determining the chunk size is a challenging task since with too big chunks we are risking having irrelevant parts of domain description in the prompt and thus decreasing the LLM performance. On the other hand, with too small chunks we are risking that the chunks will be miss-classified as they will not contain enough information about their context for deciding if they are relevant.

In result, we consider each sentence of the domain description as a one chunk since it usually contains information about one thing and later on it is easy to concatenate the relevant chunks together simply by putting them next to each other in the original order from the domain description. \\

TODO: Nepoužívat zájmeno "my", když zmiňuji nějaký obecnější problém. \\


\subsubsection{Texts comparison}
\label{texts_comparison}
We use semantic and syntactic approach. We do not use some LLM for the text comparison as it usually takes many seconds to generate the output especially when in the worst case scenario the output can be very long when a large portion of the domain description has to be copied to the output.

The semantic approach uses the ``\textit{all-MiniLM-L6-v2}'' model\footnote{\url{https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2}} that executes the described comparison in the vector space. It's intended use is a sentence and short paragraph encoder. As a comparison function we use cosine-similarity (TODO: Mám tady dát nějaký odkaz na cosine-similarity?).

The syntactic approach compares lemmas of the mentioned texts. We use the \textit{MorphoDiTa} tool \cite{Strakova2014} with the ``\textit{english-morphium-wsj-140407}'' model \cite{Straka2014}. As one word in a different contexts can have a different lemma, we lemmatize each word by word in isolation.


\subsubsection{Top k search}

In traditional RAG systems, a fixed number $k$ of the most relevant results are retrieved. However, in our specific application, $k$ is not a fixed number because the domain description may encompass a variable number of relevant sentences. To address this variability, we need to define the cosine-similarity threshold which is a value in between 0 and 1. The challenge lies in the fact that the computed cosine-similarity is always relative to the given input. Consequently, in one scenario, sentences with a cosine similarity higher than a certain threshold $x$ may be deemed relevant, while in another scenario, sentences with a cosine similarity higher than $x$ may be considered irrelevant.

We found out that our semantic RAG approach works a little bit better when setting the threshold based on the cosine-similarity of the most relevant sentence. This experiment can be found in the RAG evaluation section. (TODO: provide reference to the RAG evaluation section) \\

TODO: Asi se vyhnout nějakému zhodnocení co funguje lépe a co hůře, protože to pak bude v kapitole "Evaluation". Podobně možná můžu zmínit konkrétní použité modely až u evaluace. \\


\subsubsection{Missing context}

Our segmentation into sentences can fail when for example some sentence contains pronoun referencing anything from a different sentence. For example consider this domain description: ``The book contains a lot of pages. It is very heavy.'' and input class named ``book''. Now when considering only the second sentence it doesn't contain any syntactic information about the book therefore it most probably would be discarded by any syntactic or semantic comparison algorithm even thought for example the attribute ``weight of the book'' could be derived from it.

One possible solution is to use some language model that can accurately solve the co-reference resolution task where each pronoun is replace with the corresponding words that are referenced. This way the previous example would look like this: ``The book contains a lot of pages. The book is very heavy.''

However, we did not find any working model with a high accuracy for a various domain descriptions so instead, we implemented a simple naive solution where each sentence has it's own metadata. If a sentence starts with a pronoun we insert in this metadata a reference into the previous sentence. This means that when some algorithm is testing relevancy of the sentence ``It is very heavy''. In reality it is testing relevancy of this sentence and also the previous sentence ``The book contains a lot of pages.''

Similar issue can arise when a text contains some bullet point, such as: \\

``The book contains:
\begin{itemize}
\item info about it's author
\item date of publication''
\end{itemize}

In this case each of the bullet points will have in it's metadata reference to the sentence before the first bullet points which in this case is ``The book contains:'' and the problem is solved.

However, other issues can appear such as unexpressed subject. In these cases the domain description can be either manually edited or the domain description filtering can be temporarily disabled.