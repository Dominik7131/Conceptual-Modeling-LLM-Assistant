\chapter{Evaluation}

\section{Challenges}
\begin{itemize}
\item one element can be modeled in a various ways
\item for our purposes no existing tool for automated evaluating
\end{itemize}


\section{Limitations}
\begin{itemize}
\item we used one domain modeling expert for evaluation
\item we did preliminary experiments on most of the configurations with one shorter and one longer domain description and then used more domain descriptions for the most promising configurations
\end{itemize}


\section{Data}
%An~example citation: \cite{Andel07}

In our application we work with domain descriptions to generate suggestions. \\

Data, se kterými pracujeme:
\begin{itemize}
\item popisy domén
\item anotované popisy domén \\
\end{itemize}

TODO:
\begin{itemize}
\item jak data vypadají, tedy jednotlivé styly (educational, atd.)
\item možná jak byla vytvořena (především ručně z nějakého vygenerovaného základu od ChatGPT-3.5)
\item tabulka s počtem tříd, atributů, asociací
\item (jeden popis domény používáme pro N-shot prompting)
\item zdůvodnit, k čemu máme anotované popisy domén
\end{itemize}


\section{User evaluation}

TODO: asi nejspíš obrázek z článku a popis, který v základu bude vycházet z článku

\section{RAG evaluation}

TODO: Co nám vyšlo za recall, precision a F1 skóre, když jsme měřili naše RAG filtrovací varianty \\


\section{Generated domain elements evaluation}
(= generated classes, attributes, associations evaluation)

TODO: subsekce se všemi těmi různými pravidly, podle kterých jsme vyhodnocovali recall a precision \\

\section{Descriptions evaluation}
